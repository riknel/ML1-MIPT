{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26898</td>\n",
       "      <td>richardepryor</td>\n",
       "      <td>@treasaint salad stuff, some chillis, whatever...</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27635</td>\n",
       "      <td>reese</td>\n",
       "      <td>@sunnyjamiel sunny, I'm a workin' on it. It's ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3036</td>\n",
       "      <td>mutedriposte</td>\n",
       "      <td>@jolynnchew so early??</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5604</td>\n",
       "      <td>sakizzie_1102</td>\n",
       "      <td>So now, I have conjunctivitis in my left eye. ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36111</td>\n",
       "      <td>poptrash</td>\n",
       "      <td>Out and about in Deal, Kent. More sunshine req...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         author  \\\n",
       "0       26898  richardepryor   \n",
       "1       27635          reese   \n",
       "2        3036   mutedriposte   \n",
       "3        5604  sakizzie_1102   \n",
       "4       36111       poptrash   \n",
       "\n",
       "                                             content  sentiment  \n",
       "0  @treasaint salad stuff, some chillis, whatever...  happiness  \n",
       "1  @sunnyjamiel sunny, I'm a workin' on it. It's ...    neutral  \n",
       "2                             @jolynnchew so early??   surprise  \n",
       "3  So now, I have conjunctivitis in my left eye. ...    sadness  \n",
       "4  Out and about in Deal, Kent. More sunshine req...       love  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', encoding='latin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32823</td>\n",
       "      <td>valicast</td>\n",
       "      <td>Good Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16298</td>\n",
       "      <td>btb103</td>\n",
       "      <td>I just put my computer up on craigslist. I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28505</td>\n",
       "      <td>anavil</td>\n",
       "      <td>in ten minutes shopping   demi lovato-back aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6689</td>\n",
       "      <td>ritwik1st</td>\n",
       "      <td>From twitterberry moved to ubertwitter - suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26893</td>\n",
       "      <td>TightFreebies</td>\n",
       "      <td>@thriftymom TEAR*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         author                                            content\n",
       "0  32823       valicast                                       Good Morning\n",
       "1  16298         btb103  I just put my computer up on craigslist. I've ...\n",
       "2  28505         anavil  in ten minutes shopping   demi lovato-back aro...\n",
       "3   6689      ritwik1st  From twitterberry moved to ubertwitter - suffe...\n",
       "4  26893  TightFreebies                                  @thriftymom TEAR*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных <br>\n",
    "функция processing при надобности убирает <br>\n",
    "1)ссылки<br>\n",
    "2)указатели на чьи-то id(например, @jolynnchew)<br>\n",
    "3)стоп-слова<br>\n",
    "4)заменяет слова типа \"'m\", \"'ll\", \"'t\", \"'re\" , \"'s\" на \" am\", \" will\", \" not\", \" are\", \" is\"<br>\n",
    "\n",
    "находит: <br>\n",
    "1)кол-во ссылок в сообщении<br>\n",
    "2)кол-во указаний на имена<br>\n",
    "3)массив смайлов, присутствующих в предложении <br>\n",
    "4)кол-во восклицательных знаков <br>\n",
    "5)кол-во вопросительных знаков <br>\n",
    "6)кол-во троеточий\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#находим кол-во различных смайлов\n",
    "def smiles(text):\n",
    "    smiles = []\n",
    "    smiles_count = np.zeros(15)\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s];\\)', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]:\\)', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]= \\)', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]:\\(', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]:-D', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]:0', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]-_-', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]8\\)', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]:^\\)', text))\n",
    "    smiles.append(re.findall(r'[A-Za-z\\s]=\\(', text))\n",
    "    smiles.append(re.findall(r\"[A-Za-z\\s]=D\", text))\n",
    "    smiles.append(re.findall(r\"[A-Za-z\\s]\\)\\)\", text))\n",
    "    smiles.append(re.findall(r\"[A-Za-z\\s]:3\", text))\n",
    "    smiles.append(re.findall(r\"[A-Za-z\\s]:\\*\", text))\n",
    "    smiles.append(re.findall(r\"[A-Za-z\\s]:-\\*\", text))\n",
    "    \n",
    "    \n",
    "    for i, smile in enumerate(smiles):\n",
    "        smiles_count[i] = len(smile)\n",
    "        \n",
    "    return smiles_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing(text, links=True, id_names=True, stop_words=True, apostrophe=True):\n",
    "    stopwords_ = stopwords.words('english')\n",
    "    new_text = text\n",
    "    if links:\n",
    "        new_text = re.sub(r'https?:?//[A-Za-z0-9/.]+', '', text)\n",
    "        \n",
    "    if id_names:\n",
    "        new_text = re.sub(r'@[A-Za-z0-9]+', '', new_text)\n",
    "        \n",
    "    if apostrophe:\n",
    "        new_text = re.sub(\"'m\", ' am', new_text)\n",
    "        new_text = re.sub(\"'ll\", ' will', new_text)\n",
    "        new_text = re.sub(\"'t\", ' not', new_text)\n",
    "        new_text = re.sub(\"'re\", ' are', new_text)\n",
    "        new_text = re.sub(\"'s\", ' is', new_text)\n",
    "        new_text = re.sub(\"'\", '', new_text)\n",
    "        \n",
    "    text_words = np.array(re.findall(r\"[\\w']+\", new_text))\n",
    "    if stop_words:\n",
    "        text_words = [str(word).lower() for word in text_words if str(word).lower() not in stopwords_]\n",
    "    \n",
    "    #считаем кол-во ссылок и указаний на имена \n",
    "    count_links = len(re.findall(r'https?:?//[A-Za-z0-9/.]+', text))\n",
    "    count_id_names = len(re.findall(r'@[A-Za-z0-9]+', text))\n",
    "    \n",
    "    #считаем кол-во вопр/воск знаков и троеточий\n",
    "    count_exclamation_mark = len(re.findall(r'!', text))\n",
    "    count_question_mark = len(re.findall(r'\\?', text))\n",
    "    count_ellipsis = len(re.findall(r'\\.\\.\\.', text))\n",
    "    \n",
    "    #находим массив смайлов\n",
    "    smiles_count = smiles(text)\n",
    "    return ' '.join(text_words), count_links, count_id_names, count_exclamation_mark, count_question_mark, count_ellipsis, smiles_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделяем некоторые фичи\n",
    "Самыми хорошими на кросс-валидации оказались следующие фичи: <br>\n",
    "1) длина предложения <br>\n",
    "2)кол-во указаний на имена <br>\n",
    "3)кол-во ?<br>\n",
    "4)кол-во !<br>\n",
    "5)массив из смайлов<br>\n",
    "\n",
    "При этом из текстов были удалены указания на имена и апострофная запись заменена на нормальную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370292a5c06f47cb81eaad7643bae1da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733b529343464abbab516f0a49e28e2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_train = []\n",
    "features_test = []\n",
    "\n",
    "texts_words = []\n",
    "texts_words_test = []\n",
    "\n",
    "for text in tqdm_notebook(df.content):\n",
    "    text_words, count_links, count_id_names, count_exclamation, count_question, count_ellipsis, smiles_count = processing(text, links=False, id_names=True, stop_words=False, apostrophe=True)\n",
    "    texts_words.append(text_words)\n",
    "    features = []\n",
    "    features.append(len(text_words))\n",
    "    features.append(count_id_names)\n",
    "    features.append(count_exclamation)\n",
    "    features.append(count_question)\n",
    "    for smile in smiles_count:\n",
    "        features.append(smile)\n",
    "\n",
    "    features_train.append(features)\n",
    "\n",
    "for text in tqdm_notebook(df_test.content):\n",
    "    text_words, count_links, count_id_names, count_exclamation, count_question, count_ellipsis, smiles_count = processing(text, links=False, id_names=True, stop_words=False, apostrophe=True)\n",
    "    texts_words_test.append(text_words)\n",
    "    features = []\n",
    "    features.append(len(text_words))\n",
    "    features.append(count_id_names)\n",
    "    features.append(count_exclamation)\n",
    "    features.append(count_question)\n",
    "    for smile in smiles_count:\n",
    "        features.append(smile)\n",
    "    features_test.append(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oбучаем TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=2, max_df=0.85, max_features=3290)\n",
    "vect.fit(np.hstack((np.array(texts_words), np.array(texts_words_test))))\n",
    "matrix_train = vect.transform(np.array(texts_words))\n",
    "matrix_test = vect.transform(np.array(texts_words_test))\n",
    "\n",
    "features_train = np.hstack((features_train, matrix_train.A))\n",
    "features_test = np.hstack((features_test, matrix_test.A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = df.sentiment\n",
    "y = encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratio = {0:300, 1:300, 2:1000, 3:1000, 4:2000, 5:4500, 6:1500, 7:4000, 8:6455, 9:2000, 10:4000, 11:2500, 12:6366}\n",
    "# sampler = RandomOverSampler(ratio=ratio)\n",
    "# X, y = sampler.fit_sample(np.array(features_train), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(features_train, y)\n",
    "predictions = clf.predict(features_test)\n",
    "\n",
    "predictions_sentiment = encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happiness', 'worry', 'worry', ..., 'sadness', 'worry', 'neutral'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем ответ в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32823</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16298</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28505</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6689</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26893</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  sentiment\n",
       "0  32823  happiness\n",
       "1  16298      worry\n",
       "2  28505      worry\n",
       "3   6689    neutral\n",
       "4  26893    neutral"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = pd.read_csv('sampleSubmission.csv')\n",
    "answers['sentiment'] = np.array(predictions_sentiment)\n",
    "answers.to_csv('attempt1.csv',  index=False)\n",
    "answers.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
